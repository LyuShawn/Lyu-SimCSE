{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用于对语料库及wiki数据库进行查询进行查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算语料库的平均长度\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "file_path = 'data/wiki1m_knowledge.txt'\n",
    "\n",
    "# 读取文本文件，并计算每个句子的长度\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    sentence_word_counts = [len(line.strip().split()) for line in file]\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "sentence_word_counts_array = np.array(sentence_word_counts)\n",
    "\n",
    "# 计算中位数\n",
    "median = np.median(sentence_word_counts_array)\n",
    "\n",
    "# 计算众数\n",
    "mode = int(np.argmax(np.bincount(sentence_word_counts_array)))\n",
    "\n",
    "# 计算平均数\n",
    "mean = np.mean(sentence_word_counts_array)\n",
    "\n",
    "# 计算最大值和最小值\n",
    "max_value = np.max(sentence_word_counts_array)\n",
    "min_value = np.min(sentence_word_counts_array)\n",
    "\n",
    "print(\"中位数:\", median)\n",
    "print(\"众数:\", mode)\n",
    "print(\"平均数:\", mean)\n",
    "print(\"最大值:\", max_value)\n",
    "print(\"最小值:\", min_value)\n",
    "\n",
    "# 画频率分布图\n",
    "\n",
    "# 绘制直方图\n",
    "plt.hist(sentence_word_counts, bins=100, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Sentence Lengths')\n",
    "plt.xlabel('Length of Sentences')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert prompt test\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "path = '/pretrain_model/bert-base-uncased'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(path)\n",
    "model = BertModel.from_pretrained(path)\n",
    "text = \"Example sentence to be tokenized.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "print(outputs.last_hidden_state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "import os\n",
    "\n",
    "# 下载并加载BERT模型\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 将模型移动到指定的目录\n",
    "output_dir = 'pretrain_model/bert-base-uncased'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "model.save_pretrained(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import SequenceTagger\n",
    "from flair.data import Sentence\n",
    "import json\n",
    "import flair\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "flair.device = torch.device('cuda')\n",
    "# 加载NER模型\n",
    "tagger = SequenceTagger.load(\"ner\")\n",
    "\n",
    "input_file = '../data/wiki1m_for_simcse.txt'\n",
    "output_file = '../data/wiki1m_for_simcse_ner.json'\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "result = []\n",
    "\n",
    "for i in tqdm(range(0, len(lines), batch_size)):\n",
    "    sentence_list = []\n",
    "    for line in lines[i:i+batch_size]:\n",
    "        sentence_list.append(Sentence(line))\n",
    "\n",
    "    tagger.predict(sentence_list, mini_batch_size=128, verbose=False)\n",
    "\n",
    "\n",
    "    for sentence in sentence_list:\n",
    "        entities_list = []\n",
    "        for i, entity in enumerate(sentence.get_spans('ner')):\n",
    "            entities_list.append({\n",
    "                \"text\": entity.text,\n",
    "                \"start_position\": entity.start_position,\n",
    "                \"end_position\": entity.end_position,\n",
    "                \"label\": entity.get_label('ner').value, \n",
    "                \"confidence\": entity.score\n",
    "            })\n",
    "        result.append({\"text\": sentence.to_original_text(), \"entities\": entities_list})\n",
    "\n",
    "# 保存结果\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    json.dump(result, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# # 2024-10-11 10:52:22,912 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据梳理\n",
    "import json\n",
    "import os\n",
    "\n",
    "input_file = '../data/wiki1m_for_simcse_ner.json'\n",
    "output_file = '../data/wiki1m_for_simcse_ner_entity.txt'\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as file:\n",
    "    sentence_list = json.load(file)\n",
    "\n",
    "entity_list = []\n",
    "for sentence in sentence_list:\n",
    "    for entity in sentence['entities']:\n",
    "        entity_list.append(entity)\n",
    "\n",
    "print(\"实体数量:\", len(entity_list))\n",
    "\n",
    "# 去重\n",
    "entity_set = set()\n",
    "for entity in entity_list:\n",
    "    entity_set.add(entity['text'])\n",
    "\n",
    "print(\"去重后的实体数量:\", len(entity_set))\n",
    "# 实体数量: 1977083\n",
    "# 去重后的实体数量: 618928\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    for entity in entity_set:\n",
    "        file.write(entity + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import hashlib\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "base_dir = '../data/'\n",
    "\n",
    "input_file = base_dir + 'wiki1m_for_simcse_ner_entity.txt'\n",
    "output_dir = base_dir + 'wiki1m_for_simcse_ner_entity_search_all/'\n",
    "output_file = base_dir + 'wiki1m_for_simcse_ner_entity_search_dict.json'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as file:\n",
    "    entity_list = file.read().splitlines()\n",
    "\n",
    "entity_dict = {}\n",
    "\n",
    "# 设置 API 的基础 URL\n",
    "wikidata_url = 'https://www.wikidata.org/w/api.php'\n",
    "\n",
    "def search_wikidata(entity):\n",
    "    params = {\n",
    "        'action': 'wbsearchentities',  # 使用实体搜索\n",
    "        'format': 'json',              # 返回格式为JSON\n",
    "        'language': 'en',              # 查询语言\n",
    "        'search': entity,              # 要查询的实体名称\n",
    "        'limit': 10                    # 限制返回结果数量\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(wikidata_url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            return data.get('search', [])\n",
    "        else:\n",
    "            print(f\"Error {response.status_code}: {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying {entity}: {e}\")\n",
    "        return None\n",
    "\n",
    "def hash(text):\n",
    "    return hashlib.md5(text.encode()).hexdigest()\n",
    "\n",
    "def process_entity(entity):\n",
    "    \"\"\"\n",
    "    查询实体并保存结果到文件\n",
    "    \"\"\"\n",
    "    output_file_path = output_dir + hash(entity) + '.json'\n",
    "    if os.path.exists(output_file_path):\n",
    "        return None\n",
    "    \n",
    "    # 查询实体\n",
    "    entities = search_wikidata(entity)\n",
    "    if entities is not None:\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "            json.dump(entities, file, ensure_ascii=False, indent=4)\n",
    "    return entities\n",
    "\n",
    "# 使用线程池进行并发请求\n",
    "max_workers = 10  # 设置并发线程数量\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = [executor.submit(process_entity, entity) for entity in entity_list]\n",
    "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "        future.result()  # 等待每个任务完成\n",
    "\n",
    "# 都结束后，将所有实体信息整合到一个文件中\n",
    "entity_dict = {}\n",
    "for file in os.listdir(output_dir):\n",
    "    with open(output_dir + file, 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            entity_dict[file.split('.')[0]] = json.load(f)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    json.dump(entity_dict, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "base_dir = '../data/'\n",
    "input_dir = base_dir + 'wiki1m_for_simcse_ner_entity_search/'\n",
    "output_file = base_dir + 'wiki1m_for_simcse_ner_entity_dict.json'\n",
    "\n",
    "entity_dict = {}\n",
    "for file in tqdm(os.listdir(input_dir)):\n",
    "    with open(input_dir + file, 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            entity_dict[file.split('.')[0]] = json.load(f)\n",
    "        except:\n",
    "            print(file)\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    json.dump(entity_dict, file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_entities(entity_name):\n",
    "    \"\"\"\n",
    "    搜索 Wikipedia 上的同名实体并返回候选列表\n",
    "    :param entity_name: 实体名称\n",
    "    :return: 同名实体的候选列表，每个项包含页面 ID 和标题\n",
    "    \"\"\"\n",
    "    url = \"https://en.wikipedia.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"list\": \"search\",\n",
    "        \"srsearch\": entity_name,\n",
    "        \"format\": \"json\",\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    search_results = response.json().get(\"query\", {}).get(\"search\", [])\n",
    "    \n",
    "    candidates = [{\"page_id\": result[\"pageid\"], \"title\": result[\"title\"]} for result in search_results]\n",
    "    return candidates\n",
    "\n",
    "def fetch_entity_info(page_id):\n",
    "    \"\"\"\n",
    "    根据页面 ID 获取 Wikipedia 实体的详细信息\n",
    "    :param page_id: Wikipedia 页面 ID\n",
    "    :return: 包含实体详细信息的字典\n",
    "    \"\"\"\n",
    "    url = \"https://en.wikipedia.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"pageids\": page_id,\n",
    "        \"prop\": \"info|extracts|categories|links\",\n",
    "        \"inprop\": \"url\",\n",
    "        \"exintro\": True,\n",
    "        \"explaintext\": True,\n",
    "        \"cllimit\": \"max\",\n",
    "        \"pllimit\": \"max\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    page_info = response.json().get(\"query\", {}).get(\"pages\", {}).get(str(page_id), {})\n",
    "\n",
    "    entity_info = {\n",
    "        \"page_id\": page_id,\n",
    "        \"title\": page_info.get(\"title\", \"N/A\"),\n",
    "        \"url\": page_info.get(\"fullurl\", \"N/A\"),\n",
    "        \"extract\": page_info.get(\"extract\", \"No summary available\"),\n",
    "        \"categories\": [cat.get(\"title\", \"\") for cat in page_info.get(\"categories\", [])],\n",
    "        \"links\": [link.get(\"title\", \"\") for link in page_info.get(\"links\", [])]\n",
    "    }\n",
    "    \n",
    "    return entity_info\n",
    "\n",
    "def fetch_all_entity_infos(entity_name):\n",
    "    # 搜索同名实体的候选项\n",
    "    candidates = search_entities(entity_name)\n",
    "    if not candidates:\n",
    "        print(f\"No results found for '{entity_name}'\")\n",
    "        return\n",
    "    \n",
    "    # 获取所有候选实体的详细信息\n",
    "    all_entity_infos = []\n",
    "    for candidate in candidates:\n",
    "        print(f\"Fetching info for '{candidate['title']}' (Page ID: {candidate['page_id']})...\")\n",
    "        entity_info = fetch_entity_info(candidate[\"page_id\"])\n",
    "        all_entity_infos.append(entity_info)\n",
    "    \n",
    "    # 输出每个实体的信息\n",
    "    for info in all_entity_infos:\n",
    "        print(\"\\n页面标题:\", info['title'])\n",
    "        print(\"页面 URL:\", info['url'])\n",
    "        print(\"简介:\", info['extract'])\n",
    "        print('---')\n",
    "\n",
    "# 示例使用\n",
    "entity_name = \"Winner advances to the second stage.\"\n",
    "fetch_all_entity_infos(entity_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对假负样例进行分析\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import requests\n",
    "\n",
    "model_name = 'princeton-nlp/unsup-simcse-bert-base-uncased'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "sent_list = [\"Chamod Wickramasuriya\",\n",
    "    \"Chamod Wickramasuriya (born 27 May 1999) is a Sri Lankan cricketer.\",\n",
    "    \"He made his Twenty20 debut on 15 January 2020, for Galle Cricket Club in the 2019–20 SLC Twenty20 Tournament.\",\n",
    "    \"Comedian Bharti Singh will Host this show along with her husband writer Haarsh Limbachiyaa.\"\n",
    "    ]\n",
    "base_sent = \"hamod Wickramasuriya (born 27 May 1999) is a Sri Lankan cricketer. He made his Twenty20 debut on 15 January 2020, for Galle Cricket Club in the 2019–20 SLC Twenty20 Tournament.\"\n",
    "\n",
    "api_url = 'https://en.wikipedia.org/w/api.php'\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Wiki Study/1.0 (905899183@qq.com)\"\n",
    "}\n",
    "\n",
    "def search_wiki(text):\n",
    "    # 搜出10个结果\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"list\": \"search\",\n",
    "        \"srsearch\": text,  # 精确匹配内容\n",
    "        \"srwhat\": \"text\",         # 指定在内容中搜索\n",
    "        \"format\": \"json\",\n",
    "    }\n",
    "\n",
    "    response = requests.get(api_url, params=params, headers=headers)\n",
    "    search_results = response.json().get(\"query\", {}).get(\"search\", [])\n",
    "    \n",
    "    result = [{\"page_id\": result[\"pageid\"], \"title\": result[\"title\"]} for result in search_results]\n",
    "    return result\n",
    "\n",
    "for sent in sent_list:\n",
    "    result = search_wiki(sent)\n",
    "    print(result)\n",
    "\n",
    "# n_sent = len(sent_list)\n",
    "\n",
    "# sent_inputs = tokenizer(sent_list, return_tensors=\"pt\", padding=True)\n",
    "# base_sent_inputs = tokenizer(base_sent, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# sent_outputs = model(**sent_inputs)\n",
    "# base_sent_outputs = model(**base_sent_inputs)\n",
    "\n",
    "# sent_embeddings = sent_outputs.last_hidden_state[:, 0, :]   # cls\n",
    "# base_sent_embeddings = base_sent_outputs.last_hidden_state[:, 0, :]  # cls\n",
    "\n",
    "# cosine_similarities = F.cosine_similarity(base_sent_embeddings, sent_embeddings, dim=1)\n",
    "\n",
    "# for i in range(n_sent):\n",
    "#     print(f\"Similarity between base sentence and sentence {i + 1}: {cosine_similarities[i].item()}\")\n",
    "    \n",
    "# # sent_list 两两之间的相似度\n",
    "# cos_sim = F.cosine_similarity(sent_embeddings.unsqueeze(1), sent_embeddings.unsqueeze(0), dim=-1)\n",
    "# print(\"Similarity matrix:\")\n",
    "# print(cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每条句子搜索wiki\n",
    "import redis\n",
    "import base64\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "import base64\n",
    "\n",
    "def text_encode(text):\n",
    "    # base64 编码\n",
    "    return base64.b64encode(text.encode()).decode()\n",
    "def text_decode(text):\n",
    "    # base64 解码\n",
    "    return base64.b64decode(text.encode()).decode()\n",
    "\n",
    "# 连接到 Redis 数据库\n",
    "r = redis.Redis(host='localhost', port=6379, db=0, password='lyuredis579')\n",
    "\n",
    "prefix = 'wikisearch:'\n",
    "\n",
    "def search_wiki(text, max_proxies=10):\n",
    "    api_url = 'https://en.wikipedia.org/w/api.php'\n",
    "    # 搜出10个结果\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"list\": \"search\",\n",
    "        \"srsearch\": f'\"{text}\"',  # 精确匹配内容\n",
    "        \"srwhat\": \"text\",         # 指定在内容中搜索\n",
    "        \"format\": \"json\",\n",
    "    }\n",
    "\n",
    "    proxy = {\n",
    "        \"https\": \"http://127.0.0.1:20172\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(api_url, params=params, proxies=proxy)\n",
    "    time.sleep(random.uniform(0.05, 0.2))\n",
    "    search_results = response.json().get(\"query\", {}).get(\"search\", [])\n",
    "    \n",
    "    result = [{\"page_id\": result[\"pageid\"], \"title\": result[\"title\"]} for result in search_results]\n",
    "    return result\n",
    "\n",
    "def text_search_task(text, max=10):\n",
    "    key = prefix + text_encode(text)\n",
    "\n",
    "    if r.exists(key):\n",
    "        return json.loads(r.get(key))\n",
    "    else:\n",
    "        try:\n",
    "            result = search_wiki(text,max)\n",
    "            result = json.dumps(result, ensure_ascii=False)\n",
    "            r.set(key, result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error querying {text}: {e}\")\n",
    "            return None\n",
    "\n",
    "dataset_path = '../data/wiki1m_for_simcse.txt'\n",
    "with open(dataset_path, 'r', encoding='utf-8') as file:\n",
    "    sent_list = file.read().splitlines()\n",
    "\n",
    "# 使用线程池进行并发请求\n",
    "max_workers = 30  # 设置并发线程数量\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = [executor.submit(text_search_task, sent, max_workers) for sent in sent_list]\n",
    "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "        future.result()  # 等待每个任务完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计查询为空的句子\n",
    "import redis\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 连接 Redis 数据库\n",
    "r = redis.Redis(host='localhost', port=6379, db=0, password='lyuredis579')\n",
    "\n",
    "# 初始化计数器\n",
    "empty_list_count = 0\n",
    "total_count = 0\n",
    "prefix = 'wikisearch:'\n",
    "\n",
    "page_id_list = []\n",
    "\n",
    "# 遍历符合条件的键并统计内容为空列表的键数量\n",
    "for key in tqdm(r.scan_iter(prefix + '*')):\n",
    "    value = r.get(key)\n",
    "    # 检查值是否为空列表\n",
    "    if value is not None and value.decode() == '[]':\n",
    "        empty_list_count += 1\n",
    "    else:\n",
    "        page_id = [item['page_id'] for item in json.loads(value)]\n",
    "        page_id_list.extend(page_id)\n",
    "    total_count += 1\n",
    "print(f\"Keys with empty list content: {empty_list_count}\")\n",
    "print(f\"Total keys: {total_count}\")\n",
    "\n",
    "# 去重\n",
    "page_id_list = list(set(page_id_list))\n",
    "print(f\"Total page_id: {len(page_id_list)}\")\n",
    "\n",
    "r.set('page_id_list', json.dumps(page_id_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import redis\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "import random\n",
    "\n",
    "# 连接 Redis 数据库\n",
    "r = redis.Redis(host='localhost', port=6379, db=0, password='lyuredis579')\n",
    "\n",
    "# 初始化计数器\n",
    "empty_list_count = 0\n",
    "total_count = 0\n",
    "prefix = 'wikisearch:'\n",
    "\n",
    "page_id_list_key = 'page_id_list'\n",
    "\n",
    "if r.exists(page_id_list_key):\n",
    "    page_id_list = json.loads(r.get(page_id_list_key))\n",
    "else:\n",
    "    page_id_list = []\n",
    "\n",
    "    # 遍历符合条件的键并统计内容为空列表的键数量\n",
    "    for key in tqdm(r.scan_iter(prefix + '*'), desc='Scan keys'):\n",
    "        value = r.get(key)\n",
    "        # 检查值是否为空列表\n",
    "        if value is not None and value.decode() == '[]':\n",
    "            empty_list_count += 1\n",
    "        else:\n",
    "            page_id = [item['page_id'] for item in json.loads(value)]\n",
    "            page_id_list.extend(page_id)\n",
    "        total_count += 1\n",
    "    print(f\"Keys with empty list content: {empty_list_count}\")\n",
    "    print(f\"Total keys: {total_count}\")\n",
    "\n",
    "    # 去重\n",
    "    page_id_list = list(set(page_id_list))\n",
    "    print(f\"Total page_id: {len(page_id_list)}\")\n",
    "    r.set(page_id_list_key, json.dumps(page_id_list))\n",
    "\n",
    "r = redis.Redis(host='localhost', port=6379, db=1, password='lyuredis579')\n",
    "\n",
    "proxy = {\n",
    "    \"https\": \"http://127.0.0.1:20171\"\n",
    "}\n",
    "\n",
    "def get_detailed_page_info(page_id, language='en'):\n",
    "    url = f\"https://{language}.wikipedia.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"pageids\": page_id,\n",
    "        \"prop\": \"extracts|categories|info|images|pageprops|revisions\",\n",
    "        \"explaintext\": True,  # 返回纯文本格式\n",
    "        \"inprop\": \"url\",      # 包含页面的URL信息\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, params=params, proxies=proxy)\n",
    "        time.sleep(random.uniform(0.05, 0.2))\n",
    "        data = response.json()\n",
    "        \n",
    "        page_data = data['query']['pages'][str(page_id)]\n",
    "        \n",
    "        # 将详细信息提取到字典中\n",
    "        page_info = {\n",
    "            \"title\": page_data.get(\"title\"),\n",
    "            \"summary\": page_data.get(\"extract\"),  # 页面简介或全部内容\n",
    "            \"url\": page_data.get(\"fullurl\"),      # 页面URL\n",
    "            \"categories\": [cat['title'] for cat in page_data.get(\"categories\", [])],\n",
    "            \"images\": [img['title'] for img in page_data.get(\"images\", [])],  # 图片标题\n",
    "            \"wikidata_id\": page_data.get(\"pageprops\", {}).get(\"wikibase_item\")\n",
    "        }\n",
    "        \n",
    "        return page_info\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying page ID {page_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "prefix = 'wikipage:'\n",
    "for page_id in tqdm(page_id_list, desc='Request page info'):\n",
    "    key = prefix + str(page_id)\n",
    "    if r.exists(key):\n",
    "        continue\n",
    "    page_info = get_detailed_page_info(page_id)\n",
    "    if page_info is not None:\n",
    "        r.set(key, json.dumps(page_info, ensure_ascii=False))\n",
    "\n",
    "def get_page_info(page_id):\n",
    "    key = prefix + str(page_id)\n",
    "    if not r.exists(key):\n",
    "        page_info = get_detailed_page_info(page_id)\n",
    "        if page_info is not None:\n",
    "            r.set(key, json.dumps(page_info, ensure_ascii=False))\n",
    "\n",
    "# 使用线程池进行并发请求\n",
    "max_workers = 30  # 设置并发线程数量\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = [executor.submit(get_page_info, page_id) for page_id in page_id_list]\n",
    "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "        future.result()  # 等待每个任务完成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查询尝试\n",
    "import json\n",
    "import redis\n",
    "from tqdm import tqdm\n",
    "import base64\n",
    "\n",
    "r = redis.Redis(host='localhost', port=6379, db=0, password='lyuredis579')\n",
    "\n",
    "def text_encode(text):\n",
    "    # base64 编码\n",
    "    return base64.b64encode(text.encode()).decode()\n",
    "\n",
    "page_dict = {}\n",
    "prefix = 'wikisearch:'\n",
    "\n",
    "input_file = '../data/wiki1m_for_simcse.txt'\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as file:\n",
    "    sent_list = file.read().splitlines()\n",
    "\n",
    "sent_list = sent_list[:256]\n",
    "\n",
    "for sent in tqdm(sent_list):\n",
    "    key = prefix + text_encode(sent)\n",
    "    if r.exists(key):\n",
    "        page_dict[sent] = json.loads(r.get(key))\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"title\": \"YMCA in South Australia\",\n",
      "    \"summary\": \"South Australia (SA) has a unique position in Australia's history as, unlike the other states which were founded as colonies, South Australia began as a self governing province. Many were attracted to this and Adelaide and SA developed as an independent and free thinking state.\\nThe compound of philosophical radicalism, evangelical religion and self reliant ability typical of its founders had given an equalitarian flavour to South Australian thinking from the beginning.\\nIt was into this social setting that in February 1850 a meeting was called primarily for the formation of an Association (apparently meaning a Y.M.C.A.) for apprentices and others, after their day's work, to enjoy books, lectures, discussions, readings, friendly relief and recreation for a leisure hour. In September 1850 records show that this became \\\"The Young Men's Christian Association of South Australia\\\" as evidenced by a member's letter in London Y.M.C.A. Report 1851.\\nThere was no census in 1850, but the 1851 census put the total population of South Australia at 63,700 with males numbering 35,302.\\nThe discovery of gold in Ballarat caused a large migration from South Australia and by 1852 some 8000 had left for the Goldfields. As a consequence the various YMCA groups that had become established failed and by 1870 none remained.\\n\\\"The next available authentic record of an Association in South Australia does not appear until some members of London Y.M.C.A. coming to Adelaide, joined with ex members of the defunct original Adelaide Branch, and also members of the Brompton Association. A meeting of promoters was also held at Presbyterian Church. They became associated in the Exchange Room of the Adelaide Town Hall (now the Queen Adelaide Room)  on November 28th, 1878 at a public meeting for the promotion of a revival of the Y.M.C.A. in Adelaide. Sir John Colton (a member of the Adelaide Association in 1853 and a founder of Prince Alfred College) had been asked to preside, but was absent through illness and the chair was occupied by Mr. Richard Searle (a managing partner of D & W Murray and Co) who became the first President of the Association. A committee was formed to draft a constitution, later drawn up and signed by 585 Adelaide young men.\\\"\\nSince that time the YMCA has operated continuously, been part of the fabric of the state and served the community of South Australia.\\nLeading the YMCA was regarded as a calling and attracted men of compassion and social conscience. Not known as chief executive officers until the 1990s, they were known as General Secretaries.\\nWith the YMCA of Adelaide one of the very early organisations for social good it attracted some of the state's leading influential figures to its board and men of high calibre as General Secretary.\\nThe history of the organisation in South Australia is very much tied to the leadership by both General Secretaries (CEOs) and the presidents along with the boards who backed them.\\n\\n\\n== General Secretaries and CEO's ==\\n1879 - H.H. Birt. appointed by the board on a part-time basis. Birt oversaw activities in the temporary premises, Salisbury Chambers in king William Street and to manage the alteration of the newly leased premises in Gawler Place which opened 27 August 1879.\\n1880 -1886 Alex A Walker. Walker was secretary of the Flinders Street Presbyterian Men's Society which merged into the YMCA with him continuing as General Secretary. In 1886 the annual report of the YMCA indicated a lack of funds and Walker confessed to having appropriated £1288/16/7. In court and before Chief Justice Sir Samuel Way, Walker revealed the money had gone on assisting impecunious young men. Walker was regarded as a very hard working Secretary who said he did not have a night off in any month and the board believed he did not have fraudulent intent but compassion rather than criminality. He was sent to jail for 4 years hard labour.\\n1886 - 1900 John James Virgo. The 'new' YMCA building in Gawler Place was opened in 1884 and in 1886 the Glenelg born Virgo was appointed General Secretary following the conviction of the previous General Secretary for embezzling funds.  In 1888 the YMCA began Our Boys Institute for work among boys 13 to 18 years of age. For young men, activities included Bible classes, sporting teams, lectures, debating and choral societies, a gymnasium, camps and an employment and immigration department. Virgo was prominent in Adelaide's religious life and conducted evangelistic services on Sunday evenings at the Theatre Royal in Hindley Street.1900 Virgo became secretary of the Australasian Union of Y.M.C.A.s and 1903 was appointed secretary of the Y.M.C.A., Sydney then General Secretary of the London Central Y.M.C.A. in 1911. Virgo wrote his memoirs in 1939. He died in 1956.\\n1905 - 1916 H.A Wheeler. Wheeler was a capable administrator who adapted the programmes and emphasis to the times. Much of the evangelical work was dropped to focus on the work with young men. In 1908 Wheeler left for two years to work with the YMCA in America. This forged a link with North American YMCA's and more modern methods of physical development and a rapid development of membership. An employment department was formed in 1912 fulfilling an important social welfare role especially for young male migrants. At the outbreak of WW1 Wheeler took the initiative in promoting a nation-wide War Services Y.M.C.A. organisation and later was placed in charge of all Australian War Services in the European Zone. WW1 saw the Adelaide YMCA support YMCA staff overseas as evidenced by a letter to Wheeler from Menza camp Egypt by Col S Price Weir OC 10th battalion. by1916 The army Department was the largest work done by the Adelaide YMCA with operations at Mitcham, Cheltenham, Balaklava, Murray Bridge, Torrens Island, Gawler. The YMCA provided comfort, counselling and recreation to the troops. YMCA war services were funded by public donation and during this time in South Australia £199,185 was raised.\\n1908 -1910 - H.S. Stafford acting General Secretary. Stafford, an American from Dayton Ohio was working at the Bendigo YMCA and took the acting role while Wheeler spent 2 years working for the YMCA in the United States His work transformed the organisation as recognised in a speech by the then President Henry J Holden who said of him. \\\".. it was not an association of Christian young men but a Christian association for all young men\\\"\\n1916 -1920 The title of General Secretary was discontinued this period as post war the organisation needed to adjust having been dominated by the military units. Two officers controlled the organisation. M.U. Maddern was secretary to the Army Department and R Taylor became Secretary of the General Department. This gave lack of continuity at the top at a time when the planning for transition to peace time was so important.\\n1920 Jack Tolston Massey. Jack Massey began his YMCA career as a field secretary attached to the Australian Imperial Forces A Christian (Anglican) and a pacifist he served in England France and Belgium assisting soldiers awaiting repatriation. He was appointed as General Secretary of the Adelaide YMCA in 1920 and went on to build and expand the organisation as well as develop programmes and advocate for young people with accomplishments including establishing a court for juvenile offenders and guiding amateur football in SA. He also provided support for British Boys brought out to help in agriculture. He attended the 100 years of Adelaide YMCA in 1978 not long before his death in 1981 and was acclaimed as one of the great men of the organisation and the community for his life of service.\\n1939 - 1960 Alf Gibbs . During WW1 Alf Gibbs served as YMCA War Services Department Chief Commissioner overseeing YMCA staff in almost all military camps and some 62 representative overseas to assist the troops. Gibbs was appointed General Secretary Adelaide YMCA after some negotiations with the Adelaide YMCA Board while Alf was in India. He oversaw the expansion of the YMCA and the sale of the Gawler Place building. In 1956 he negotiated the purchase of the Presbyterian Church in Flinders Street which was demolished the following year and a new modern YMCA youth complex and residential facility was constructed. Gibbs led the fundraising that enabled the construction of YMCA youth facilities at Walkerville (demolished 12-18 September 2024), Kilburn, Elizabeth and Glenelg. In 1945 \\\"Loftia Park,\\\" a large block of land in the lovely Mount Lofty Ranges, was purchased with swimming pool, tennis courts, sports grounds and other facilities partly completed.\\n1960s\\nGraeme Irvine. Irvine was an evangelical Christian and developed in the Adelaide YMCA a group of similar thinking leaders.  Ultimately this became exclusive and counterproductive.  He went on to build up World Vision Australia and then to New York where he grew the organisation into a large multinational NGO. Irvine was in 1978 among the signers of the Declaration of Internationalization, which declared a set of objectives for World Vision in its operations throughout the world.  In 1988, Irvine became the first non-American president of World Vision International.\\nJim Daly. came from Woodside army camp where he was a YMCA army officer. After his Army service he joined the Adelaide Y as Extension Secretary under Irvine having responsibility for developing boards, programmes and ensuring the viability of Walkerville, Northern Districts (Kilburn), West Croydon and Elizabeth Branches. He was a senior leader at the first Kangaroo Island Camp and many others in preceding years. They were initially organised initially by Don McCallum, Physical Education Director and in following years by Ross Baxter Glen Powell, Gary Kelly, Dean Manning, Dave Badger, Tim Looker. The Kangaroo Island Camps ran for nearly 40 years. Daly's particular interest was in Adventure Camping. He personally led groups of senior leaders on Outward Bound-type expeditions to New Zealand, Tasmania (Cradle Mountain Track, Flinders Ranges and the Grampians). Daly went on become a Senior Office, then Assistant Director in the newly formed South Australian Government Department of Tourism, Recreation and Sport. He also completed his Master of Health at UNISA. Daly continues his involvement in the Y as a Life Member.\\nDaly wrote an Honours Thesis on \\\"The Adelaide YMCA: 1879-1934\\\". This thesis studied the changing role to the Y the 1st World War, and Depression. A copy is available from the YMCA SA office and will be eventually online. Daly also authored a book \\\"Recreation and Sport Planning and Design.\\\"\\n1970s\\nGlen Powell. Powell came to Australia with his family in about 1970 and worked under Daly until he became CEO. He was ex-Chicago YMCA and only came for \\\"a couple of years\\\".  50 year later he is still here living in Adelaide. Powell was a transformational leader of the organisation. Powell was a man of ideas and happy to experiment with new programme initiatives. He transformed camping into a massive co-ed programme, introduced Explorers and Adventurers which at its peak had about 1000 families involved. He set up the first child safety programme \\\"Alert Assert\\\" which was rolled out in schools. He negotiated the first PPP at Aberfoyle Hub which was a three way collaboration with the Council, Govt and YMCA. Other initiatives included Dollar Day a door knocking fundraiser and the City Port Fun Run which attracted thousands of runners.\\n1980s\\nTrevor Cleland. Was promoted from accountant to CEO with limited success. This created a crisis which inspired the recruitment to the board of some former Y members high in the corporate world who could use there expertise to review the organisation. Clive Armour (CEO of ETSA) Colin Williamson (CEO of Strategic Resources Consulting). A restructure of the organisation and shaking off the old Methodist mentality about paying people for their 'calling'. The board upped the salary offering from $19,000 to $52,000 and went to market for a new CEO.\\nRob Dowling 1990? - 2003. Dowling came from Carclew Performing Arts and became our first leaders called a CEO as the others were titled General Secretaries. Dowling was a transformational leader and kept all the Y programmes running at a high level and established a Registered Training Organisation running certificate course out of the Flinders Street headquarters. With the Flinders Street property becoming outdated and run down Dowling sought to redevelop site.. A 12-story, strata titled building with the Y having some floors and selling off others. Plans were drawn by Woodhead Australia and funding partners sought. Brilliant idea but the board was not able to pull it off. The Flinders' Street property was then sold as cost of fire compliance and the age of the building proved uneconomical to refurbish. Closing the residential wing affected the organisations cash flow. Dowling sought to purchase another building, an old bank, but not supported by the Board. Dowling left to undertake teaching and research at Flinders University before retirement to the Adelaide hills.\\nDave Bedson: Held the position for a short time.\\n2000s\\nMike Kelly.  Driven by the board policy Kelly spent his time trying to win contracts for student accommodation which was an emerging area of service due to the growing numbers of overseas students in Adelaide. This chewed up significant funds which ultimately delivered no results and the money from the sale of Flinders Street property began to diminish. Changing time saw the diminishing of the camping programme and Explorers and Adventurers.\\nPeter Schwartz. A former footballer, Schwartz did some very good work, won the Aquadome contract and set up a Community Strengthening unit, after school care and negotiated access to Home and Community Care grant funding to expand YMCA social services.\\nHaydn Robins. 2012 -  2019 Robins came from Vic Y. He transformed the organisation into a modern competitive management organisation, running sport,  aquatic and community centres across South Australia. Supported by a senior leadership team he assembled, he took the organisation from near insolvency to financial security and a higher level of service delivery. Robins had an accomplished career as a footballer playing AFL and SANFL. While CEO, Robins instituted \\\"reciprocal rights\\\" which made the facilities across South Australia available to any resident in the state rather than being limited to the closest YMCA. In addition, under his leadership the Fleurieu Aquatic Centre offered free memberships to children under ten in an effort to combat childhood obesity.\\nAndrew Mundy - Acting CEO 2019. Mundy stepped in at short notice from his role as General manager Operations and earned his name on the baton that is passed from one CEO to the next. In 2020 the Covid pandemic struck sending the community into various lockdowns and causing YMCA facilities to shut and then impose limits on proximity. Andrew played a key role in managing the organisation through the crisis.\\nDavid Paterson - Commenced in January 2020, 100 years after the appointment of Jack Massey. He has previously served as Chief Innovation Officer of World Vision, Chief Marketing Officer of Medibank Private, and Chief Strategy Officer of a multinational marketing agency group. David is a co-founder of Social Capital and the Committee for Adelaide. He is also a former Professor of Innovation & Enterprise at UniSA, a past board member of YMCA Victoria, and is one of the co-founders of YMCA Victoria's The Bridge Project, which has helped reduce juvenile recidivism from 65% to 3%. Early into his tenure David was faced with the COVID pandemic which struck in March 2020 causing a crisis for the organisation.\\n\\n\\n== References ==\\n\\n\\n== External links ==\\nYMCA South Australia homepage\\nTwitter\\nYouth Parliament Instagram\\nThe Bridge Project\\nHome and Community Care (HACC) program\",\n",
      "    \"url\": \"https://en.wikipedia.org/wiki/YMCA_in_South_Australia\",\n",
      "    \"categories\": [\n",
      "        \"Category:All articles with unsourced statements\",\n",
      "        \"Category:Articles with unsourced statements from August 2023\",\n",
      "        \"Category:CS1 maint: unfit URL\",\n",
      "        \"Category:History of South Australia\",\n",
      "        \"Category:Non-profit organisations based in South Australia\",\n",
      "        \"Category:Use dmy dates from October 2022\",\n",
      "        \"Category:YMCA\"\n",
      "    ],\n",
      "    \"images\": [],\n",
      "    \"wikidata_id\": \"Q85816499\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# page信息测试\n",
    "import json\n",
    "import redis\n",
    "\n",
    "page_id = 62653684\n",
    "prefix = 'wikipage:'\n",
    "\n",
    "r = redis.Redis(host='localhost', port=6379, db=0, password='lyuredis579')\n",
    "\n",
    "key = prefix + str(page_id)\n",
    "value = r.get(key)\n",
    "if value is not None:\n",
    "    page_info = json.loads(value)\n",
    "    print(json.dumps(page_info, ensure_ascii=False, indent=4))\n",
    "    # summary = page_info.get('summary', '')\n",
    "    # l = len(summary.split())\n",
    "    # print(l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整理数据分布\n",
    "import json\n",
    "import redis\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import base64\n",
    "\n",
    "r = redis.Redis(host='localhost', port=6379, db=0, password='lyuredis579')\n",
    "\n",
    "sent_id_list = r.get('page_id_list')\n",
    "sent_id_list = json.loads(sent_id_list)\n",
    "\n",
    "# 获取最大值和最小值\n",
    "max_value = np.max(sent_id_list)\n",
    "min_value = np.min(sent_id_list)\n",
    "\n",
    "def text_encode(text):\n",
    "    # base64 编码\n",
    "    return base64.b64encode(text.encode()).decode()\n",
    "\n",
    "\n",
    "with open('../data/wiki1m_for_simcse.txt', 'r', encoding='utf-8') as file:\n",
    "    sent_list = file.read().splitlines()\n",
    "\n",
    "data = []\n",
    "for i, sent in tqdm(enumerate(sent_list), desc='Query'):\n",
    "    key = 'wikisearch:' + text_encode(sent)\n",
    "    if r.exists(key):\n",
    "        page_id_list = json.loads(r.get(key))\n",
    "        page_id_list = [item['page_id'] for item in page_id_list]\n",
    "        data.append(page_id_list)\n",
    "    else:\n",
    "        data.append([])\n",
    "#     if i == 1000:\n",
    "#         break\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计batch内相关度\n",
    "import numpy as np\n",
    "\n",
    "bs = 256\n",
    "num_batches = len(data) // bs\n",
    "\n",
    "for i in range(num_batches):\n",
    "    batch_data = data[i * bs: (i + 1) * bs]\n",
    "    batch_score = 0.0\n",
    "    for page_id_list in batch_data:\n",
    "        if len(page_id_list) == 0:\n",
    "            continue\n",
    "        score = len(set(page_id_list) & set(sent_id_list)) / len(set(page_id_list) | set(sent_id_list))\n",
    "        batch_score += score\n",
    "\n",
    "total_page_id_list = 0\n",
    "total_page_unique_list = 0\n",
    "for i in range(num_batches):\n",
    "    batch_data = data[i * bs: (i + 1) * bs]\n",
    "    batch_page_id_list = [item for sublist in batch_data for item in sublist]\n",
    "    batch_page_unique_list = list(set(batch_page_id_list))\n",
    "    total_page_id_list += len(batch_page_id_list)\n",
    "    total_page_unique_list += len(batch_page_unique_list)\n",
    "    if len(batch_page_unique_list) == 0:\n",
    "        continue\n",
    "    # 计算batch内的page重复率\n",
    "    print(f\"Batch {i}: {len(batch_page_unique_list) / len(batch_page_id_list)}\")\n",
    "print(f\"Total: {total_page_unique_list / total_page_id_list}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simcse3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
